?POIX1t
?POIXlt
?POSIXlt
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
NewsTrain$PubDate = strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTest$PubDate = strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S")
summary(NewsTrain$PubDate)
summary(NewsTrain$PubDate[1])
NewsTrain$PubDate[1]
print(NewsTrain$PubDate[1])
summary(NewsTrain$PubDate[1], digits = 15)
NewsTrain$PubDate[1].sec
NewsTrain$PubDate[1]$sec
NewsTrain$PubDate[1]$min
summary(NewsTrain)
summary(NewsTrain$PubDate$year)
NewsTrain$PubDate$year
NewsTrain$PubDate$year[1]
summary(NewsTrain$PubDate$min)
summary(NewsTrain$PubDate$wday)
summary(NewsTrain$PubDate$yday)
summary(NewsTrain$PubDate$year)
summary(NewsTest$PubDate$year)
summary(NewsTest$PubDate[1].year
summary(NewsTest$PubDate[1].year)
summary(NewsTest$PubDate[1]$year)
summary(NewsTest$PubDate)
summary(NewsTrain$PubDate)
source(file.path(Sys.getenv("HOME"), "work/mit15.071x/work/functions", "tf_frame.R"))
tf_frame
tf_frame
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
str(NewsTrain)
tf = tf_frame(NewsTrain$Abstract)
source(file.path(Sys.getenv("HOME"), "work/mit15.071x/work/functions", "tf_frame.R"))
tf = tf_frame(NewsTrain$Abstract)
nrow(tf)
inspect(tf[1:3], [1:5])
inspect(tf[1:3, 1:5])
str(tf)
colnames(tf)[1]
colnames(tf)[2]
colnames(tf)[3]
colnames(tf)[4]
colnames(tf)[5]
colnames(tf)[6]
colnames(tf)[7]
colnames(tf)[8]
colnames(tf)[80]
colnames(tf)[8000]
colnames(tf)[600]
colnames(tf)[800]
ncol(tf)
which.max(tf$X100th)
NewsTrain$Abstract[3258]
tf$Popular = NewsTrain$Popular
library(caTools)
split = sample.split(tf$Popular, SplitRatio = 0.7)
train = subset(tf, split == TRUE)
test = subset(tf, split == FALSE)
tf_train = subset(tf, split == TRUE)
tf_test = subset(tf, split == FALSE)
rm(train)
rm(test)
tf_train = subset(tf, split == TRUE)
tf_test = subset(tf, split == FALSE)
k = 7
k = 7
tf_kmeans = kmeans(tf_train, centers = k) #, iter.max = 1000)
tf_cl_kmeans <- list()
for (i in 1:k) {
tf_cl_kmeans[[i]] = subset(tf_train, tf_kmeans$cluster == i)
}
for (i in 1:length(tf_cl_kmeans)) {
cat(i, ":", nrow(tf_cl_kmeans[[i]]), "\n")
print(tail(sort(colMeans(tf_cl_kmeans[[i]]))))
}
nrow(tf_train)
nrow(tf_test)
split = sample.split(tf$Popular, SplitRatio = 0.7)
tf_train = subset(tf, split == TRUE)
nrow(tf_test)
nrow(tf_train)
table(tf$Popular)
table(split)
nrow(tf_train)
nrow(tf_test)
tf_train = subset(tf, split==TRUE)
nrow(tf_train)
nrow(spliy)
nrow(split)
length(split)
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
tf = tf_frame(NewsTrain$Abstract)
tf$Popular = NewsTrain$Popular
library(caTools)
split = sample.split(tf$Popular, SplitRatio = 0.7)
tf_train = subset(tf, split == TRUE)
nrow(tf_train)
set.seed(123)
split = sample.split(tf$Popular, SplitRatio = 0.7)
tf_train = subset(tf, split == TRUE)
nrow(tf_train)
summary(tf$Popular)
table(split)
tf_train
tf_a = subset(tf, Popular == 1)
nrow(tf_a)
table(split)
tf_a$split = split
length(tf$Popular)
length(split)
tf_a$split = split
str(tf$Popular)
str(split)
tf_a$a = split
tf_a = tf
tf_a$split = split
tf_x = subset(tf_a, split == TRUE)
nrow(tf_x)
nrow(tf_train)
split = sample.split(tf$Popular, SplitRatio = 0.7)
train = subset(tf, split == TRUE)
nrow(train)
?sample.split
tf$split = split
tf_train = subset(tf, split == TRUE)
tf_train = subset(tf, split == TRUE)row(tf_train)
nrow(tf_train)
nrow(tf_test)
tf_test = subset(tf, split == FALSE)
l
s
ls
ls()
rm tf_a
rm(tf_a)
rm(tf_x)
tf$split = NULL
k = 7
tf_kmeans = kmeans(tf_train, centers = k) #, iter.max = 1000)
tf_cl_kmeans <- list()
